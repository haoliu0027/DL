{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper Reproduction - \"Image-to-Image Translation with Conditional Adversarial Networks\"\n",
    "\n",
    "> By $\\;\\;\\;$   Xu Yingfu           $\\;\\;\\;\\;\\;$            Zeng Liang              $\\;\\;\\;\\;\\;$            Liu Hao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图片引用格式(可以在这加我们最后的对比图片)\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/1/1b/Creative-Tail-Animal-dog.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many problems in image processing, computer graphics and computer vision can be regarded as a problem that translate an input image into image. GANs is a of paramount method to implement the image translating. However, how effective image-conditional GANs can be as a general-purpose solition for image-to-image translation remains unclear. In this case, conditional GANs has been proposed in the paper [1] (https://arxiv.org/pdf/1611.07004.pdf) which is used to explore the effectness of image-condition GANs. And in that paper, it achives a reasonable result on a wide variety of problems('Labels to Street Scene', 'Labels to Facade', 'BW to Color', 'Aerial to Map', 'Day to Night' and 'Edges to Photo').\n",
    "\n",
    "By inspired by this paper, we would like to reproduce this paper to gain a deeper insight by following three critria: \n",
    "\n",
    "- New code variant (Rewrite existing code to be more efficient/readable)\n",
    "- New data (Evaluating different datasets to obtain similar result)\n",
    "- Hyperparamter check (Evaluating sensitivity to hyperparameters)\n",
    "\n",
    "In this blog, we will walk through the following:\n",
    "\n",
    "- 2. Code Description for New code variant: we only illustrate the significant changed part of code \n",
    "- 3. New dataset: what dataset we choose and why choose this dataset\n",
    "- 4. The results of the New dataset\n",
    "- 5. Hyperparameter check: Due to limited time, we only choose \n",
    "- 6. Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Code Description for New code variant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we rewrite the existing code from the readability and the efficiency two aspects.\n",
    "\n",
    "- Readability: In the [orginal code](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix) of paper [1], it mixes of \"pix2pix\" model code and \"CycleGAN\" model code which is quite difficult for readers to follow its logic. For example, the `Resnet` architecture is redundant in the \"pix2pix\" model.  In addition, we rewrite the code into modularity (dataset, dataloader, libraries, parameters, network, train, test). Which gives us a clear logic.\n",
    "\n",
    "\n",
    "- Efficiency: In the [original code](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix) of paper [1], the dataset format is troublesome Since the dataset we found are usually separate pictures and the picture size is unique. In this case, much time spents on changing picture size and combine pictures by `combine_A_and_B.py`. Inspired by the [github code](https://github.com/mrzhu-cool/pix2pix-pytorch), we change the data format like the following. We don not need to change the data size and preprocess the dataset by `combine_A_and_B.py`.  \n",
    "                           1st class folder:        - facades \n",
    "                           2nd class folder:      - test  - train\n",
    "                           3rd class folder:        - a     - a\n",
    "                           3rd class folder:        - b     - b\n",
    "                                \n",
    "                                   \n",
    "In the Appendix, the detailed explanation of the code will be inllustrated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. New dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The results of the New dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blurry dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chinese characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In China, there are different writing style for Chinese characters. So from this intuition, training the model to see if the changes of writing style on Chinese characters is meaningful. As for the dataset, we download from a Chinese character website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In this section, the result of the new dataset has been shown whose paramters are exactly same as the parameters in the paper[1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Appendix\n",
    "<font color = 'red'>\n",
    "    \n",
    "\n",
    "我明天加详细的注释\n",
    "<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Library used**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from math import log10\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import init\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.backends.cudnn as cudnn\n",
    "import functools\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **setting parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the dataset in the current directory\n",
    "dataset = 'facades'\n",
    "\n",
    "batch_size = 1\n",
    "test_batch_size=1\n",
    "# direction of the dataset\n",
    "direction='b2a'\n",
    "# number of channels\n",
    "input_nc=3\n",
    "output_nc=3\n",
    "# the number of filters in the first conv layer\n",
    "ngf=64\n",
    "ndf=64\n",
    "\n",
    "epoch_count=1\n",
    "niter=100\n",
    "niter_decay=100\n",
    "\n",
    "lr=0.0002\n",
    "lr_policy='lambda'\n",
    "lr_decay_iters=30\n",
    "beta1=0.5\n",
    "\n",
    "threads=0\n",
    "seed=123\n",
    "lamb=10\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "# this is the cpu version\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "# if using the gpu, open the following code\n",
    "torch.cuda.manual_seed(seed)\n",
    "device = torch.device(\"cuda: 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Funtions for loading dataset and preprocessing**\n",
    "\n",
    "In this section, we change the dataset input format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in [\".png\", \".jpg\", \".jpeg\"])\n",
    "\n",
    "def load_img(filepath):\n",
    "    img = Image.open(filepath).convert('RGB')\n",
    "    img = img.resize((256, 256), Image.BICUBIC)\n",
    "    return img\n",
    "\n",
    "def save_img(image_tensor, filename):\n",
    "    image_numpy = image_tensor.float().numpy()\n",
    "    image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0\n",
    "    image_numpy = image_numpy.clip(0, 255)\n",
    "    image_numpy = image_numpy.astype(np.uint8)\n",
    "    image_pil = Image.fromarray(image_numpy)\n",
    "    image_pil.save(filename)\n",
    "    print(\"Image saved as {}\".format(filename))\n",
    "\n",
    "\n",
    "# Inherit the data.Dataset and create a new dataset for getting each item easily\n",
    "class DatasetFromFolder(data.Dataset):\n",
    "    \n",
    "    def __init__(self, image_dir, direction):\n",
    "        super(DatasetFromFolder, self).__init__()\n",
    "        self.direction = direction\n",
    "        self.a_path = join(image_dir, \"a\")\n",
    "        self.b_path = join(image_dir, \"b\")\n",
    "        self.image_filenames = [x for x in listdir(self.a_path) if is_image_file(x)]\n",
    "\n",
    "        transform_list = [transforms.ToTensor(),\n",
    "                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "        self.transform = transforms.Compose(transform_list)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # covert into RGB picture, do they cover the original pictures?\n",
    "        # Answer: this is just converting the original pictures \n",
    "        # join : combine each paths in the list \n",
    "        # Preprocessing of the pictures\n",
    "        a = Image.open(join(self.a_path, self.image_filenames[index])).convert('RGB')\n",
    "        b = Image.open(join(self.b_path, self.image_filenames[index])).convert('RGB')\n",
    "        # Resize\n",
    "        a = a.resize((286, 286), Image.BICUBIC)\n",
    "        b = b.resize((286, 286), Image.BICUBIC)\n",
    "        # To tensor\n",
    "        a = transforms.ToTensor()(a)\n",
    "        b = transforms.ToTensor()(b)\n",
    "        # add a offset to the picture\n",
    "        w_offset = random.randint(0, max(0, 286 - 256 - 1))\n",
    "        h_offset = random.randint(0, max(0, 286 - 256 - 1))\n",
    "    \n",
    "        a = a[:, h_offset:h_offset + 256, w_offset:w_offset + 256]\n",
    "        b = b[:, h_offset:h_offset + 256, w_offset:w_offset + 256]\n",
    "        # Normalize\n",
    "        a = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))(a)\n",
    "        b = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))(b)\n",
    "        \n",
    "      \n",
    "        if random.random() < 0.5:\n",
    "            idx = [i for i in range(a.size(2) - 1, -1, -1)]\n",
    "            idx = torch.LongTensor(idx)\n",
    "            a = a.index_select(2, idx)\n",
    "            b = b.index_select(2, idx)\n",
    "\n",
    "        if self.direction == \"a2b\":\n",
    "            return a, b\n",
    "        else:\n",
    "            return b, a\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Design Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_nc, ngf, norm_layer, use_bias\n",
    "# reflectionPad2d : 使用的填充宽度是3，填充结果和原来的数组相比宽、高都要加4，这一点是没问题的，\n",
    "# 只不过并不是使用0来填充。如果仔细观察的话，可以发现使用的是镜像填充的方法，\n",
    "# 以边界的一行或者一列为对称轴，就可以发现两规律了\n",
    "class Inconv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, norm_layer, use_bias):\n",
    "        super(Inconv, self).__init__()\n",
    "        self.inconv = nn.Sequential(\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=7, padding=0,\n",
    "                      bias=use_bias),\n",
    "            norm_layer(out_ch),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.inconv(x)\n",
    "        return x\n",
    "# ngf, ngf * 2, norm_layer, use_bias\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, norm_layer, use_bias):\n",
    "        super(Down, self).__init__()\n",
    "        self.down = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3,\n",
    "                      stride=2, padding=1, bias=use_bias),\n",
    "            norm_layer(out_ch),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.down(x)\n",
    "        return x\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, norm_layer, use_bias):\n",
    "        super(Up, self).__init__()\n",
    "        self.up = nn.Sequential(\n",
    "            # nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            # nn.Conv2d(in_ch, out_ch,\n",
    "            #           kernel_size=3, stride=1,\n",
    "            #           padding=1, bias=use_bias),\n",
    "            nn.ConvTranspose2d(in_ch, out_ch,\n",
    "                               kernel_size=3, stride=2,\n",
    "                               padding=1, output_padding=1,\n",
    "                               bias=use_bias),\n",
    "            norm_layer(out_ch),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.up(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Outconv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(Outconv, self).__init__()\n",
    "        self.outconv = nn.Sequential(\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=7, padding=0),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.outconv(x)\n",
    "        return x\n",
    "\n",
    "def init_net(net, init_type='normal', init_gain=0.02, gpu_id='cuda:0'):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        net.to(gpu_id)\n",
    "        init_weights(net, init_type, gain=init_gain)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **gernerator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetSkipConnectionBlock(nn.Module):\n",
    "    \"\"\"Defines the Unet submodule with skip connection.\n",
    "        X -------------------identity----------------------\n",
    "        |-- downsampling -- |submodule| -- upsampling --|\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, outer_nc, inner_nc, input_nc=None,\n",
    "                 submodule=None, outermost=False, innermost=False, norm_layer=nn.BatchNorm2d, use_dropout=False):\n",
    "        \"\"\"Construct a Unet submodule with skip connections.\n",
    "\n",
    "        Parameters:\n",
    "            outer_nc (int) -- the number of filters in the outer conv layer\n",
    "            inner_nc (int) -- the number of filters in the inner conv layer\n",
    "            input_nc (int) -- the number of channels in input images/features\n",
    "            submodule (UnetSkipConnectionBlock) -- previously defined submodules\n",
    "            outermost (bool)    -- if this module is the outermost module\n",
    "            innermost (bool)    -- if this module is the innermost module\n",
    "            norm_layer          -- normalization layer\n",
    "            use_dropout (bool)  -- if use dropout layers.\n",
    "        \"\"\"\n",
    "        super(UnetSkipConnectionBlock, self).__init__()\n",
    "        self.outermost = outermost\n",
    "        if type(norm_layer) == functools.partial:\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "        if input_nc is None:\n",
    "            input_nc = outer_nc\n",
    "        downconv = nn.Conv2d(input_nc, inner_nc, kernel_size=4,\n",
    "                             stride=2, padding=1, bias=use_bias)\n",
    "#对输入的每一个元素运用$f(x) = max(0, x) + {negative_slope} * min(0, x)$\n",
    "#参数：\n",
    "    # negative_slope：控制负斜率的角度，默认等于0.01\n",
    "    # inplace-选择是否进行覆盖运算\n",
    "        downrelu = nn.LeakyReLU(0.2, True)\n",
    "        downnorm = norm_layer(inner_nc)\n",
    "        uprelu = nn.ReLU(True)\n",
    "        upnorm = norm_layer(outer_nc)\n",
    "\n",
    "        if outermost:\n",
    "            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc,\n",
    "                                        kernel_size=4, stride=2,\n",
    "                                        padding=1)\n",
    "            down = [downconv]\n",
    "            up = [uprelu, upconv, nn.Tanh()]\n",
    "            model = down + [submodule] + up\n",
    "        elif innermost:\n",
    "            upconv = nn.ConvTranspose2d(inner_nc, outer_nc,\n",
    "                                        kernel_size=4, stride=2,\n",
    "                                        padding=1, bias=use_bias)\n",
    "            down = [downrelu, downconv]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "            model = down + up\n",
    "        else:\n",
    "            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc,\n",
    "                                        kernel_size=4, stride=2,\n",
    "                                        padding=1, bias=use_bias)\n",
    "            down = [downrelu, downconv, downnorm]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "\n",
    "            if use_dropout:\n",
    "                model = down + [submodule] + up + [nn.Dropout(0.5)]\n",
    "            else:\n",
    "                model = down + [submodule] + up\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.outermost:\n",
    "            return self.model(x)\n",
    "        else:   # add skip connections\n",
    "            return torch.cat([x, self.model(x)], 1)\n",
    "    \n",
    "\n",
    "    \n",
    "class UnetGenerator(nn.Module):\n",
    "    \"\"\"Create a Unet-based generator\"\"\"\n",
    "\n",
    "    def __init__(self, input_nc, output_nc, num_downs, ngf=64, norm_layer=nn.BatchNorm2d, use_dropout=False):\n",
    "        \"\"\"Construct a Unet generator\n",
    "        Parameters:\n",
    "            input_nc (int)  -- the number of channels in input images\n",
    "            output_nc (int) -- the number of channels in output images\n",
    "            num_downs (int) -- the number of downsamplings in UNet. For example, # if |num_downs| == 7,\n",
    "                                image of size 128x128 will become of size 1x1 # at the bottleneck\n",
    "            ngf (int)       -- the number of filters in the last conv layer\n",
    "            norm_layer      -- normalization layer\n",
    "\n",
    "        We construct the U-Net from the innermost layer to the outermost layer.\n",
    "        It is a recursive process.\n",
    "        \"\"\"\n",
    "        super(UnetGenerator, self).__init__()\n",
    "        # construct unet structure\n",
    "        unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=None, \n",
    "                                             norm_layer=norm_layer, innermost=True)  # add the innermost layer\n",
    "        for i in range(num_downs - 5):          # add intermediate layers with ngf * 8 filters\n",
    "            unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=unet_block, \n",
    "                                                 norm_layer=norm_layer, use_dropout=use_dropout)\n",
    "        # gradually reduce the number of filters from ngf * 8 to ngf\n",
    "        unet_block = UnetSkipConnectionBlock(ngf * 4, ngf * 8, input_nc=None, submodule=unet_block, \n",
    "                                             norm_layer=norm_layer)\n",
    "        unet_block = UnetSkipConnectionBlock(ngf * 2, ngf * 4, input_nc=None, submodule=unet_block, \n",
    "                                             norm_layer=norm_layer)\n",
    "        unet_block = UnetSkipConnectionBlock(ngf, ngf * 2, input_nc=None, submodule=unet_block, \n",
    "                                             norm_layer=norm_layer)\n",
    "        self.model = UnetSkipConnectionBlock(output_nc, ngf, input_nc=input_nc, submodule=unet_block, \n",
    "                                             outermost=True, norm_layer=norm_layer)  # add the outermost layer\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Standard forward\"\"\"\n",
    "        return self.model(input)\n",
    "\n",
    "    \n",
    "def define_G(input_nc, output_nc, ngf, norm='batch', use_dropout=False, init_type='normal', init_gain=0.02, gpu_id='cuda:0'):\n",
    "    net = None\n",
    "    norm_layer = get_norm_layer(norm_type=norm)\n",
    "\n",
    "#     net = ResnetGenerator(input_nc, output_nc, ngf, norm_layer=norm_layer, use_dropout=use_dropout, n_blocks=9)\n",
    "    net = UnetGenerator(input_nc, output_nc, 8, ngf, norm_layer=norm_layer, use_dropout=use_dropout)\n",
    "    return init_net(net, init_type, init_gain, gpu_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Discriminator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLayerDiscriminator(nn.Module):\n",
    "    def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d, use_sigmoid=False):\n",
    "        super(NLayerDiscriminator, self).__init__()\n",
    "        if type(norm_layer) == functools.partial:\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        kw = 4\n",
    "        padw = 1\n",
    "        sequence = [\n",
    "            nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "\n",
    "        nf_mult = 1\n",
    "        nf_mult_prev = 1\n",
    "        for n in range(1, n_layers):\n",
    "            nf_mult_prev = nf_mult\n",
    "            nf_mult = min(2**n, 8)\n",
    "            sequence += [\n",
    "                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult,\n",
    "                          kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n",
    "                norm_layer(ndf * nf_mult),\n",
    "                nn.LeakyReLU(0.2, True)\n",
    "            ]\n",
    "\n",
    "        nf_mult_prev = nf_mult\n",
    "        nf_mult = min(2**n_layers, 8)\n",
    "        sequence += [\n",
    "            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult,\n",
    "                      kernel_size=kw, stride=1, padding=padw, bias=use_bias),\n",
    "            norm_layer(ndf * nf_mult),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "\n",
    "        sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)]\n",
    "\n",
    "        if use_sigmoid:\n",
    "            sequence += [nn.Sigmoid()]\n",
    "\n",
    "        self.model = nn.Sequential(*sequence)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "\n",
    "\n",
    "class PixelDiscriminator(nn.Module):\n",
    "    def __init__(self, input_nc, ndf=64, norm_layer=nn.BatchNorm2d, use_sigmoid=False):\n",
    "        super(PixelDiscriminator, self).__init__()\n",
    "        if type(norm_layer) == functools.partial:\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        self.net = [\n",
    "            nn.Conv2d(input_nc, ndf, kernel_size=1, stride=1, padding=0),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(ndf, ndf * 2, kernel_size=1, stride=1, padding=0, bias=use_bias),\n",
    "            norm_layer(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(ndf * 2, 1, kernel_size=1, stride=1, padding=0, bias=use_bias)]\n",
    "\n",
    "        if use_sigmoid:\n",
    "            self.net.append(nn.Sigmoid())\n",
    "\n",
    "        self.net = nn.Sequential(*self.net)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.net(input)\n",
    "    \n",
    "def define_D(input_nc, ndf, netD,\n",
    "             n_layers_D=3, norm='batch', use_sigmoid=False, init_type='normal', init_gain=0.02, gpu_id='cuda:0'):\n",
    "    net = None\n",
    "    norm_layer = get_norm_layer(norm_type=norm)\n",
    "\n",
    "    if netD == 'basic':\n",
    "        net = NLayerDiscriminator(input_nc, ndf, n_layers=3, norm_layer=norm_layer, use_sigmoid=use_sigmoid)\n",
    "    elif netD == 'n_layers':\n",
    "        net = NLayerDiscriminator(input_nc, ndf, n_layers_D, norm_layer=norm_layer, use_sigmoid=use_sigmoid)\n",
    "    elif netD == 'pixel':\n",
    "        net = PixelDiscriminator(input_nc, ndf, norm_layer=norm_layer, use_sigmoid=use_sigmoid)\n",
    "    else:\n",
    "        raise NotImplementedError('Discriminator model name [%s] is not recognized' % net)\n",
    "\n",
    "    return init_net(net, init_type, init_gain, gpu_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **init_param, loss fn, optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(net, init_type='normal', gain=0.02):\n",
    "    def init_func(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
    "            if init_type == 'normal':\n",
    "                init.normal_(m.weight.data, 0.0, gain)\n",
    "            elif init_type == 'xavier':\n",
    "                init.xavier_normal_(m.weight.data, gain=gain)\n",
    "            elif init_type == 'kaiming':\n",
    "                init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "            elif init_type == 'orthogonal':\n",
    "                init.orthogonal_(m.weight.data, gain=gain)\n",
    "            else:\n",
    "                raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                init.constant_(m.bias.data, 0.0)\n",
    "        elif classname.find('BatchNorm2d') != -1:\n",
    "            init.normal_(m.weight.data, 1.0, gain)\n",
    "            init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "    print('initialize network with %s' % init_type)\n",
    "    net.apply(init_func)\n",
    "\n",
    "\n",
    "\n",
    "def get_norm_layer(norm_type='instance'):\n",
    "    if norm_type == 'batch':\n",
    "        norm_layer = functools.partial(nn.BatchNorm2d, affine=True)\n",
    "    elif norm_type == 'instance':\n",
    "        norm_layer = functools.partial(nn.InstanceNorm2d, affine=False, track_running_stats=False)\n",
    "    elif norm_type == 'switchable':\n",
    "        norm_layer = SwitchNorm2d\n",
    "    elif norm_type == 'none':\n",
    "        norm_layer = None\n",
    "    else:\n",
    "        raise NotImplementedError('normalization layer [%s] is not found' % norm_type)\n",
    "    return norm_layer\n",
    "\n",
    "\n",
    "class GANLoss(nn.Module):\n",
    "    def __init__(self, use_lsgan=True, target_real_label=1.0, target_fake_label=0.0):\n",
    "        super(GANLoss, self).__init__()\n",
    "        self.register_buffer('real_label', torch.tensor(target_real_label))\n",
    "        self.register_buffer('fake_label', torch.tensor(target_fake_label))\n",
    "        if use_lsgan:\n",
    "            self.loss = nn.MSELoss()\n",
    "        else:\n",
    "            # binary cross entropy\n",
    "            self.loss = nn.BCELoss()\n",
    "\n",
    "    def get_target_tensor(self, input, target_is_real):\n",
    "        if target_is_real:\n",
    "            target_tensor = self.real_label\n",
    "        else:\n",
    "            target_tensor = self.fake_label\n",
    "        return target_tensor.expand_as(input)\n",
    "\n",
    "    def __call__(self, input, target_is_real):\n",
    "        target_tensor = self.get_target_tensor(input, target_is_real)\n",
    "        return self.loss(input, target_tensor)\n",
    "    \n",
    "def update_learning_rate(scheduler, optimizer):\n",
    "    scheduler.step()\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    print('learning rate = %.7f' % lr)  \n",
    "\n",
    "# learning rate decay\n",
    "def get_scheduler(optimizer):\n",
    "    if lr_policy == 'lambda':\n",
    "        def lambda_rule(epoch):\n",
    "            lr_l = 1.0 - max(0, epoch + epoch_count - niter) / float(niter_decay + 1)\n",
    "            return lr_l\n",
    "        scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)\n",
    "    elif lr_policy == 'step':\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=lr_decay_iters, gamma=0.1)\n",
    "    elif lr_policy == 'plateau':\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, threshold=0.01, patience=5)\n",
    "    elif lr_policy == 'cosine':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=opt.niter, eta_min=0)\n",
    "    else:\n",
    "        return NotImplementedError('learning rate policy [%s] is not implemented', opt.lr_policy)\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot1 = \"datasets/facades/train\"\n",
    "dataroot2 = \"datasets/facades/test\"\n",
    "# As for windows, delete num_works parameter\n",
    "training_data_loader = DataLoader(dataset=DatasetFromFolder(dataroot1, direction), num_workers=threads, batch_size=batch_size, shuffle=True)\n",
    "testing_data_loader = DataLoader(dataset=DatasetFromFolder(dataroot2, direction), num_workers=threads, batch_size=test_batch_size)\n",
    "\n",
    "\n",
    "print('===> Building models')\n",
    "\n",
    "'''loading the generator and discriminator'''\n",
    "net_g = define_G(input_nc, output_nc, ngf, 'batch', False, 'normal', 0.02, gpu_id=device)\n",
    "net_d = define_D(input_nc + output_nc, ndf, 'basic', gpu_id=device)\n",
    "\n",
    "'''set loss fn'''\n",
    "criterionGAN = GANLoss().to(device)\n",
    "criterionL1 = nn.L1Loss().to(device)\n",
    "criterionMSE = nn.MSELoss().to(device)\n",
    "\n",
    "'''setup optimizer''' \n",
    "optimizer_g = optim.Adam(net_g.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizer_d = optim.Adam(net_d.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "'''set the learning rate adjust policy'''\n",
    "net_g_scheduler = get_scheduler(optimizer_g)\n",
    "net_d_scheduler = get_scheduler(optimizer_d)\n",
    "\n",
    "'''training process'''\n",
    "for epoch in range(epoch_count, niter + niter_decay + 1):\n",
    "    \n",
    "    for iteration, batch in enumerate(training_data_loader, 1):\n",
    "        # forward\n",
    "        real_a, real_b = batch[0].to(device), batch[1].to(device)\n",
    "        fake_b = net_g(real_a)\n",
    "\n",
    "        ######################\n",
    "        # (1) Update D network\n",
    "        ######################\n",
    "\n",
    "        optimizer_d.zero_grad()\n",
    "        \n",
    "        # D train with fake\n",
    "        fake_ab = torch.cat((real_a, fake_b), 1)\n",
    "        pred_fake = net_d.forward(fake_ab.detach())\n",
    "        loss_d_fake = criterionGAN(pred_fake, False)\n",
    "\n",
    "        # D train with real\n",
    "        real_ab = torch.cat((real_a, real_b), 1)\n",
    "        pred_real = net_d.forward(real_ab)\n",
    "        loss_d_real = criterionGAN(pred_real, True)\n",
    "        \n",
    "        # Combined D loss\n",
    "        loss_d = (loss_d_fake + loss_d_real) * 0.5\n",
    "\n",
    "        loss_d.backward()\n",
    "       \n",
    "        optimizer_d.step()\n",
    "\n",
    "        ######################\n",
    "        # (2) Update G network\n",
    "        ######################\n",
    "\n",
    "        optimizer_g.zero_grad()\n",
    "\n",
    "        # First, G(A) should fake the discriminator\n",
    "        fake_ab = torch.cat((real_a, fake_b), 1)\n",
    "        pred_fake = net_d.forward(fake_ab)\n",
    "        loss_g_gan = criterionGAN(pred_fake, True)\n",
    "\n",
    "        # Second, G(A) = B\n",
    "        loss_g_l1 = criterionL1(fake_b, real_b) * lamb\n",
    "        \n",
    "        loss_g = loss_g_gan + loss_g_l1\n",
    "        \n",
    "        loss_g.backward()\n",
    "\n",
    "        optimizer_g.step()\n",
    "\n",
    "        print(\"===> Epoch[{}]({}/{}): Loss_D: {:.4f} Loss_G: {:.4f}\".format(\n",
    "            epoch, iteration, len(training_data_loader), loss_d.item(), loss_g.item()))\n",
    "\n",
    "    update_learning_rate(net_g_scheduler, optimizer_g)\n",
    "    update_learning_rate(net_d_scheduler, optimizer_d)\n",
    "\n",
    "    # test\n",
    "    avg_psnr = 0\n",
    "    for batch in testing_data_loader:\n",
    "        input, target = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "        prediction = net_g(input)\n",
    "        mse = criterionMSE(prediction, target)\n",
    "        psnr = 10 * log10(1 / mse.item())\n",
    "        avg_psnr += psnr\n",
    "    print(\"===> Avg. PSNR: {:.4f} dB\".format(avg_psnr / len(testing_data_loader)))\n",
    "\n",
    "    #checkpoint\n",
    "    if epoch % 50 == 0:\n",
    "        if not os.path.exists(\"checkpoint\"):\n",
    "            os.mkdir(\"checkpoint\")\n",
    "        if not os.path.exists(os.path.join(\"checkpoint\", dataset)):\n",
    "            os.mkdir(os.path.join(\"checkpoint\", dataset))\n",
    "        net_g_model_out_path = \"checkpoint/{}/netG_model_epoch_{}.pth\".format(dataset, epoch)\n",
    "        net_d_model_out_path = \"checkpoint/{}/netD_model_epoch_{}.pth\".format(dataset, epoch)\n",
    "        torch.save(net_g, net_g_model_out_path)\n",
    "        torch.save(net_d, net_d_model_out_path)\n",
    "        print(\"Checkpoint saved to {}\".format(\"checkpoint\" + dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-be723b2f1915>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mnepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m150\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mmodel_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"checkpoint/{}/netG_model_epoch_{}.pth\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mnet_g\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "def load_img(filepath):\n",
    "    img = Image.open(filepath).convert('RGB')\n",
    "    img = img.resize((256, 256), Image.BICUBIC)\n",
    "    return img\n",
    "\n",
    "def save_img(image_tensor, filename):\n",
    "    image_numpy = image_tensor.float().numpy()\n",
    "    image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0\n",
    "    image_numpy = image_numpy.clip(0, 255)\n",
    "    image_numpy = image_numpy.astype(np.uint8)\n",
    "    image_pil = Image.fromarray(image_numpy)\n",
    "    image_pil.save(filename)\n",
    "    print(\"Image saved as {}\".format(filename))\n",
    "\n",
    "nepochs = 150\n",
    "model_path = \"checkpoint/{}/netG_model_epoch_{}.pth\".format(dataset, nepochs)\n",
    "\n",
    "net_g = torch.load(model_path).to(device)\n",
    "\n",
    "if direction == \"a2b\":\n",
    "    image_dir = \"datasets/{}/test/a/\".format(dataset)\n",
    "else:\n",
    "    image_dir = \"datasets/{}/test/b/\".format(dataset)\n",
    "\n",
    "image_filenames = [x for x in os.listdir(image_dir) if is_image_file(x)]\n",
    "\n",
    "transform_list = [transforms.ToTensor(),\n",
    "                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "\n",
    "transform = transforms.Compose(transform_list)\n",
    "\n",
    "for image_name in image_filenames:\n",
    "    img = load_img(image_dir + image_name)\n",
    "    img = transform(img)\n",
    "    input = img.unsqueeze(0).to(device)\n",
    "    out = net_g(input)\n",
    "    out_img = out.detach().squeeze(0).cpu()\n",
    "\n",
    "    if not os.path.exists(os.path.join(\"result\", dataset)):\n",
    "        os.makedirs(os.path.join(\"result\", dataset))\n",
    "    save_img(out_img, \"result/{}/{}\".format(dataset, image_name))"
   ]
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "/nbs/blog_test.ipynb",
    "public": true
   },
   "id": ""
  },
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
